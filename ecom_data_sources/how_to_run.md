
# ğŸ›ï¸ ECOM Data Sources Microservice

This microservice generates and streams realistic e-commerce simulation data (POS logs, promotions, user activity, etc.) for downstream analytics pipelines via **batch files** or **real-time Kafka streams**.

It is containerized using **Docker**, automated with **Makefile**, orchestrated with **GitHub Actions**, and intended to be run standalone or integrated into larger ML pipelines.

---

## ğŸŒŸ Features

- ğŸ§  Generates synthetic e-commerce user, session, behavior, and order data.
- ğŸ Python-based with asynchronous real-time simulation.
- ğŸ³ Dockerized for portability and reproducibility.
- ğŸ” CI/CD pipeline via GitHub Actions to auto-build & push Docker image.
- ğŸ§ª Smart bootstrapping logic using `start_simulation.sh`:
  - Batch generation if data doesnâ€™t exist.
  - Promotion fetcher auto-start.
  - Realtime simulator launch.
---

## ğŸ§± Project Structure

```bash
ğŸ“¦ ECOM_PRJ
 â”£â”â” ğŸ“‚ others
 â”£â”â” âš™ï¸ .gitattributes
 â”£â”â” âš™ï¸ .gitignore
 â”£â”â” ğŸ“ README.md
 â”£â”â” ğŸ“‚ ecom_data_sources
 â”ƒ   â”£â”â” ğŸ“‚ external_apis
 â”ƒ   â”ƒ   â”£â”â” ğŸ“ __init__.py
 â”ƒ   â”ƒ   â”£â”â” ğŸ“ promotion_external_api_colab.py
 â”ƒ   â”ƒ   â”—â”â” ğŸ“ promotion_fetch_api_request.py
 â”ƒ   â”£â”â” ğŸ“‚ inventory
 â”ƒ   â”ƒ   â”—â”â” ğŸ“„ product_catalog.csv
 â”ƒ   â”£â”â” ğŸ“‚ json_files
 â”ƒ   â”ƒ   â”—â”â” ğŸ“ full_data.json
 â”ƒ   â”£â”â” ğŸ“‚ logs/session_logs
 â”ƒ   â”£â”â” ğŸ“‚ pos_logs
 â”ƒ   â”ƒ   â”£â”â” ğŸ“‚ __pycache__
 â”ƒ   â”ƒ   â”£â”â” ğŸ“ __init__.py
 â”ƒ   â”ƒ   â”—â”â” ğŸ“ unified_simulator.py
 â”ƒ   â”£â”â” ğŸ“‚ simulation_scripts
 â”ƒ   â”ƒ   â”£â”â” ğŸ“‚ __pycache__
 â”ƒ   â”ƒ   â”£â”â” ğŸ“ __init__.py
 â”ƒ   â”ƒ   â”£â”â” ğŸ“ behaviour.py
 â”ƒ   â”ƒ   â”£â”â” ğŸ“ historic_simulator.py
 â”ƒ   â”ƒ   â”£â”â” ğŸ“ match_persona_to_behaviour.py
 â”ƒ   â”ƒ   â”£â”â” ï¿½ï¿½ realtime_simulator.py
 â”ƒ   â”ƒ   â”—â”â” ğŸ“ simulator_logic.py
 â”ƒ   â”£â”â” ğŸ“‚ user_activity
 â”ƒ   â”ƒ   â”—â”â” ğŸ“ __init__.py
 â”ƒ   â”£â”â” ğŸ“„ .env.secrets
 â”ƒ   â”£â”â” ğŸ“„ Dockerfile
 â”ƒ   â”£â”â” ğŸ“„ Makefile
 â”ƒ   â”£â”â” ğŸ“„ requirements.txt
 â”ƒ   â”—â”â” ğŸ“„ start_simulation.sh
````

* * *

## âš™ï¸ Prerequisites

-   [Docker](https://www.docker.com/products/docker-desktop)
-   [Make](https://www.gnu.org/software/make/)
-   Python 3.11+ (for local testing)
-   DockerHub account (if pushing to registry)
-   GitHub account (for workflow triggers)
* * *

## ğŸ§ª Running the Microservice Locally

```bash
# Clone the repo
git clone https://github.com/TejasJay/ECOM_EndToEnd_DataEngineering_ML.git
cd ECOM_PRJ/ecom_data_sources

# Login to DockerHub (reads from .env.secrets)
make login

# Build the Docker image
make build

# Run the service (triggers start_simulation.sh inside container)
make run
```

* * *

## ğŸ” .env.secrets

Create `ecom_data_sources/.env.secrets` with your DockerHub credentials:

```env
DOCKERHUB_USERNAME=your_dockerhub_username
DOCKERHUB_PASSWORD=your_dockerhub_password
```

This allows `make login` and `make push` to work securely.

* * *

## ğŸš€ GitHub Actions (CI/CD)

When you `git push` to the `main` branch, this workflow triggers:

```
.github/workflows/build_simulator.yml
```

It automatically:

1.  Builds the Docker image inside GitHub runner.
2.  Logs in to DockerHub using repository secrets.
3.  Pushes the image to `docker.io/<username>/ecom_data_sources:latest`.

> ğŸ” Make sure to store DockerHub credentials as GitHub repository secrets:

-   `DOCKERHUB_USERNAME`
-   `DOCKERHUB_TOKEN`
* * *

## ğŸ“œ What `start_simulation.sh` Does

```bash
1. Checks if `json_files/full_data.json` exists:
   - If not, runs unified simulator in batch mode to generate it.
2. Checks if `promotion_fetch_api_request.py` is already running:
   - If not, starts it in the background.
3. Launches the unified simulator in real-time mode.
```

* * *

## ğŸ›  Makefile Shortcuts

```bash
make build          # Build Docker image
make run            # Run container (runs start_simulation.sh inside)
make login          # DockerHub login
make push           # Push image to DockerHub
make test           # Run batch simulator locally
make check-secrets  # Verify .env.secrets exists
```

* * *

## ğŸ“¦ Output Data

-   `json_files/full_data.json`: Batch simulated data.
-   `logs/session_logs/core*.log`: Real-time behavior logs.
-   `promotion.log`: Output of background API fetcher.
* * *

## ğŸ’¡ Future Enhancements

-   Kafka support for real-time stream publishing
-   Visualization dashboard (e.g. Grafana/Kibana)
-   Dataset metrics validation
-   Integration with Airflow or ML pipeline
* * *

## ğŸ§  Summary

This microservice simulates user and purchase data for e-commerce use cases and is structured to scale via containerization and automation. It can be extended into a full end-to-end AI pipeline for fraud detection, personalization, and forecasting.

* * *

### ğŸ“¬ Contact

Feel free to open issues or contribute via PRs if youâ€™d like to improve this microservice!



