#############################
# ğŸ“› Broker Identity
#############################

# Unique ID for this Kafka broker (should be different if running a multi-broker cluster)
broker.id=1

#############################
# ğŸ”Œ Network Interfaces
#############################

# Kafka listens on all container interfaces at port 9092


# This is what clients should use to connect (set to your host IP if remote)
# Advertise both internal Docker network & Mac host access
listeners=PLAINTEXT://0.0.0.0:9092
advertised.listeners=PLAINTEXT://host.docker.internal:9092
listener.security.protocol.map=PLAINTEXT:PLAINTEXT


#############################
# ğŸ“¦ Storage Configuration
#############################

# Directory where Kafka stores topic logs (volume mounted in docker-compose)
log.dirs=/var/lib/kafka/data

#############################
# ğŸ§  Zookeeper Connection
#############################

# Zookeeper host:port for cluster coordination (Zookeeper is another container)
zookeeper.connect=zookeeper:2181

#############################
# âš™ï¸ Threading & I/O
#############################

# Number of threads for handling client network requests
num.network.threads=3

# Number of threads for disk I/O operations
num.io.threads=8

# Socket send buffer size (bytes)
socket.send.buffer.bytes=102400

# Socket receive buffer size (bytes)
socket.receive.buffer.bytes=102400

# Max size of request Kafka can accept (100MB)
socket.request.max.bytes=104857600

#############################
# ğŸ§¹ Log Retention Settings
#############################

# Retain logs for 7 days (useful for replaying events)
log.retention.hours=168

# Kafka creates a new log segment after 1GB (helps with clean-up and compaction)
log.segment.bytes=1073741824

# Check for old segments every 5 minutes
log.retention.check.interval.ms=300000

#############################
# ğŸš¨ Message Constraints
#############################

# Max message size accepted (adjust if producers send large payloads)
message.max.bytes=1000012
