<img src="./docker_arch.png">


* * *

### ‚úÖ **PART 1: The Big Picture ‚Äî How Everything Fits Together**

#### üì¶ Components in Your Setup:

| Component | Purpose |
| --- | --- |
| `start_simulation.sh` | Shell script to orchestrate simulation steps locally or in container |
| `Dockerfile` | Containerizes the microservice |
| `Makefile` | Provides CLI interface to build/run/push Docker image |
| `.github/workflows/` | GitHub Actions CI/CD pipeline: auto-build and push image to DockerHub |
| `.env.secrets` | Keeps sensitive credentials (like DockerHub login) out of source control |

* * *

### üîÅ **High-Level Flowchart**

```plaintext
                         üßë Dev pushes code to GitHub
                                  ‚îÇ
                                  ‚ñº
                       üîÅ GitHub Actions Triggered
                                  ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Checkout ‚Üí Set up Python & Docker ‚Üí Login  ‚îÇ
         ‚îÇ  ‚Üí Build Docker Image ‚Üí Push to DockerHub  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
                 üê≥ Updated container on DockerHub

                 (Alternatively, run locally with...)
                                  ‚îÇ
                    make run ‚Üí docker run ‚Üí Dockerfile
                                  ‚îÇ
                                  ‚ñº
                üîÅ start_simulation.sh (inside container)
                  ‚îú‚îÄ if JSON doesn't exist ‚Üí batch simulation
                  ‚îú‚îÄ background API simulator
                  ‚îî‚îÄ run real-time simulator
```

* * *



## üîπ PART 2: `start_simulation.sh` ‚Äî Local + Container Brain

This script runs **inside the container** (or locally) and acts like the **brains of the simulation microservice**. It decides:

-   When to generate fresh data
-   When to clean logs
-   When to run the external API fetcher
-   When to launch the real-time simulator
* * *

### üßæ **Full Script Recap**

```bash
#!/bin/bash
set -e  # Exit on any error

# Step 1: Check if JSON already exists
if [ ! -f ./json_files/full_data.json ]; then
  echo "üõ† Generating batch data..."
  python3 -m pos_logs.unified_simulator --mode batch --count 10000 --avg_sessions 10
  echo "üßπ Cleaning session logs..."
  rm -f ./logs/session_logs/core.*
fi

# Step 2: Run external API fetcher in background if not running
if ! pgrep -f promotion_fetch_api_request.py > /dev/null; then
  echo "üîÑ Starting promotion fetch API in background..."
  nohup python3 -m external_apis.promotion_fetch_api_request > ./logs/promotion.log 2>&1 &
fi

# Step 3: Start real-time simulation
echo "üöÄ Launching real-time simulator..."
python3 -m pos_logs.unified_simulator --mode realtime --output stdout --avg_sessions 2 --concurrent_users 10
```

* * *

## üîç Line-by-Line Breakdown

| Line | What it Does |
| --- | --- |
| `#!/bin/bash` | Declares this as a bash script |
| `set -e` | Terminates the script immediately if any command fails (important for CI) |

* * *

### ‚úÖ Step 1: Batch JSON Generation

```bash
if [ ! -f ./json_files/full_data.json ]; then
```

-   Check if simulation data already exists
-   If not, generate synthetic data using:

```bash
python3 -m pos_logs.unified_simulator --mode batch --count 10000 --avg_sessions 10
```

üîß _This is a Python module command that triggers the `BatchDataSimulator`_

Then clean stale logs:

```bash
rm -f ./logs/session_logs/core.*
```

* * *

### üîÑ Step 2: Launch API Simulator (Only If Not Running)

```bash
if ! pgrep -f promotion_fetch_api_request.py > /dev/null; then
```

-   Uses `pgrep` to check if the promotion fetch script is already running
-   If not, it runs the script **in the background** with `nohup`

```bash
nohup python3 -m external_apis.promotion_fetch_api_request > ./logs/promotion.log 2>&1 &
```

üß† This simulates real-time ingestion of promotions fetched from an external API.

* * *

### üöÄ Step 3: Real-Time Simulation

```bash
python3 -m pos_logs.unified_simulator --mode realtime ...
```

This launches the real-time async/multiprocess simulator using a JSON file of users.

* * *

## üí° Why This Script is Powerful

-   Ensures **fresh data** is generated only when needed
-   Manages **background jobs** like API fetchers
-   Launches **real-time simulators** to Kafka or stdout
-   Makes your microservice **container-ready and automation-friendly**
* * *

## üí¨ Example Use Cases

| Scenario | Result |
| --- | --- |
| You run `make run` | It uses Dockerfile‚Äôs `CMD ["bash", "start_simulation.sh"]` to run this script |
| In CI/CD | This script gets run inside the container GitHub Actions builds and pushes |
| You want a new batch of data | Just delete the JSON and rerun `make run` |

* * *



## üî∏ PART 3: `Dockerfile` ‚Äì Build Your Data Microservice

Here‚Äôs the full file again for context:

```dockerfile
# Use lightweight Python image
FROM python:3.11-slim

# Set working directory inside container
WORKDIR /app

# Copy everything into the container's /app
COPY . /app

# Tell Python where to find your modules
ENV PYTHONPATH="/app"

# Install dependencies
RUN pip install --upgrade pip && pip install -r requirements.txt

# Default command to run on `docker run`
CMD ["bash", "start_simulation.sh"]
```

* * *

## üîç Step-by-Step Breakdown

### ‚úÖ `FROM python:3.11-slim`

-   This is your **base image**.
-   It's a minimal Python image (~22MB) ‚Üí faster builds, smaller size.

> Think of it like: _"Start with a clean machine that has Python 3.11 installed."_

* * *

### ‚úÖ `WORKDIR /app`

-   Sets the default directory inside the container.
-   All next commands (like `COPY`, `RUN`, `CMD`) happen **inside `/app`**.
-   Equivalent to doing `cd /app` in Linux.
* * *

### ‚úÖ `COPY . /app`

-   Copies all files from your **host's `ecom_data_sources/` directory** into the container at `/app`.

üì¶ Example:

| Host | Becomes inside container |
| --- | --- |
| `ecom_data_sources/pos_logs/` | `/app/pos_logs/` |
| `ecom_data_sources/requirements.txt` | `/app/requirements.txt` |

* * *

### ‚úÖ `ENV PYTHONPATH="/app"`

This is **super important**. Without this line:

```python
from pos_logs.unified_simulator import ...
```

‚Ä¶ would **fail**, because Python wouldn‚Äôt know where to find `pos_logs`, `simulation_scripts`, etc.

By setting `PYTHONPATH`, we‚Äôre saying:

> ‚ÄúTreat `/app` as the root of the Python module search path.‚Äù

* * *

### ‚úÖ `RUN pip install --upgrade pip && pip install -r requirements.txt`

-   First, we upgrade pip.
-   Then install all dependencies from `requirements.txt`.

üéØ This creates a **layered cache** in Docker:

-   If your requirements don‚Äôt change, it doesn‚Äôt reinstall everything again.
-   Saves build time!
* * *

### ‚úÖ `CMD ["bash", "start_simulation.sh"]`

This is the **entrypoint**.

When you do:

```bash
docker run ecom_data_sources:latest
```

‚Ä¶it will automatically execute:

```bash
bash start_simulation.sh
```

Which:

1.  Generates data if needed
2.  Starts API fetcher
3.  Starts real-time Kafka simulation
* * *

## üí¨ Real-World Analogy

> Dockerfile is like a recipe (blueprint) to bake a cake (your microservice image) that has your logic (`start_simulation.sh`), ingredients (`requirements.txt`), and behavior (`CMD`).

* * *

## üîÅ Typical Dev Flow

| Action | What Happens |
| --- | --- |
| `make build` | Uses `Dockerfile` to create an image locally |
| `make run` | Starts container which runs `start_simulation.sh` |
| GitHub Workflow | Executes `docker build` inside CI and pushes to DockerHub |

* * *


## üîπ PART 4: `Makefile` ‚Äì Automating Everything with Simple Commands

A `Makefile` lets you run complex Docker and local dev commands with just:

```bash
make build
make run
make push
```

### üìÑ Your `ecom_data_sources/Makefile`:

```makefile
-include .env.secrets

IMAGE_NAME=ecom_data_sources
TAG=latest
DOCKERHUB_USERNAME=tejasjay03

.PHONY: help build run push login test

help:
        @echo "Targets:"
        @echo "  build        - Build Docker image"
        @echo "  run          - Run the container locally"
        @echo "  login        - Docker login to DockerHub"
        @echo "  push         - Push to DockerHub"
        @echo "  test         - Run simulation locally with Python"

login:
        docker login -u $(DOCKERHUB_USERNAME) -p $(DOCKERHUB_PASSWORD)

build:
        docker build -t $(IMAGE_NAME):$(TAG) .

run:
        docker run --rm -it $(IMAGE_NAME):$(TAG)

push: build
        docker tag $(IMAGE_NAME):$(TAG) $(DOCKERHUB_USERNAME)/$(IMAGE_NAME):$(TAG)
        docker push $(DOCKERHUB_USERNAME)/$(IMAGE_NAME):$(TAG)

test:
        python3 -m pos_logs.unified_simulator --mode batch --count 10

batch:
        docker run --rm -it ecom_data_sources:latest python3 -m pos_logs.unified_simulator --mode batch --count 1000 --avg_sessions 10

realtime:
        docker run --rm -it ecom_data_sources:latest python3 -m pos_logs.unified_simulator --mode realtime --output stdout --avg_sessions 10 --concurrent_users 500

check-secrets:
        @if [ ! -f .env.secrets ]; then \
                echo "‚ùå .env.secrets file not found!"; \
                exit 1; \
        else \
                echo "‚úÖ secrets loaded from .env.secrets "; \
        fi
```

* * *

## üß† What Each Section Does

### ‚úÖ `-include .env.secrets`

-   This **includes your secrets file** with DockerHub credentials:

```makefile
DOCKERHUB_USERNAME=tejasjay03
DOCKERHUB_PASSWORD=your_dockerhub_token
```

-   So you can use `$(DOCKERHUB_USERNAME)` and `$(DOCKERHUB_PASSWORD)` directly.
* * *

### ‚úÖ Variable Section

```makefile
IMAGE_NAME=ecom_data_sources
TAG=latest
```

-   These help reuse values across the Makefile instead of hardcoding.
-   Want to version it? Just change `TAG=1.0.1`.
* * *

### ‚úÖ `.PHONY`

```makefile
.PHONY: build run push
```

-   Prevents conflicts with real file names.
-   You‚Äôre saying: ‚ÄúThese are **commands**, not actual files.‚Äù
* * *

## üõ† Commands You Can Run

### üîπ `make build`

```makefile
docker build -t ecom_data_sources:latest .
```

-   Runs your Dockerfile and builds the image locally.
* * *

### üîπ `make run`

```makefile
docker run --rm -it ecom_data_sources:latest
```

-   Runs your image (which will trigger `start_simulation.sh` inside Docker).
* * *

### üîπ `make login`

```makefile
docker login -u tejasjay03 -p your_dockerhub_token
```

-   Logs into DockerHub using creds in `.env.secrets`.
* * *

### üîπ `make push`

```makefile
docker tag ecom_data_sources:latest tejasjay03/ecom_data_sources:latest
docker push tejasjay03/ecom_data_sources:latest
```

-   Pushes the image to your DockerHub repository.
* * *

### üîπ `make test`

-   Runs a quick local batch simulation to verify logic.

### üîπ `make batch` / `make realtime`

-   For advanced, mode-specific Docker testing.
* * *

### üß™ Real-Life Example Workflow

| Task | Run This | What Happens |
| --- | --- | --- |
| You make a code change | `make build` | Docker image is rebuilt |
| You want to test locally | `make run` | Container starts |
| You want to publish | `make push` | Image gets pushed to DockerHub |
| You want to automate | GitHub runs `docker build` + `docker push` via CI |  |

* * *



## üîπ PART 6: `.github/workflows/build_simulator.yml` ‚Äì Automated Build & Push with Every Git Push

This file triggers **automated Docker builds and pushes** to DockerHub every time code changes inside your `ecom_data_sources` microservice.

* * *

### üìÑ Your Current Workflow:

```yaml
name: Build & Push Data Sources Microservice

on:
  push:
    paths:
      - 'ecom_data_sources/**'
      - '.github/workflows/build_simulator.yml'

  workflow_dispatch:

jobs:
  build-push:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: buildx-${{ github.sha }}

      - name: Docker Login
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and Push Docker Image
        run: |
          cd ecom_data_sources
          docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/ecom_data_sources:latest .
          docker push ${{ secrets.DOCKERHUB_USERNAME }}/ecom_data_sources:latest
```

* * *

## üí° Why This Workflow Matters

| Feature | Purpose |
| --- | --- |
| `on: push` | Triggers on changes to your microservice or the workflow file |
| `workflow_dispatch` | Allows manual runs from GitHub UI |
| `checkout@v3` | Pulls your code onto the GitHub runner |
| `setup-python` | Ensures Python (for pip install, etc.) is available |
| `docker/setup-buildx-action` | Enables faster Docker builds with caching |
| `actions/cache` | Speeds up rebuilds by reusing previous layers |
| `docker/login-action` | Logs into DockerHub securely using **GitHub Secrets** |
| `docker build & push` | Your microservice gets built and deployed automatically |

* * *

## üîí Secrets Setup

These values come from **GitHub ‚Üí Settings ‚Üí Secrets and variables ‚Üí Actions**:

| Secret Name | Value |
| --- | --- |
| `DOCKERHUB_USERNAME` | `tejasjay03` |
| `DOCKERHUB_TOKEN` | \[your DockerHub token\] |

**Tip**: You can generate a Docker token here:
üëâ [https://hub.docker.com/settings/security](https://hub.docker.com/settings/security)

* * *

## üîÅ End-to-End Flow

```text
                 You make a change
                         ‚¨á
           GitHub detects the change via `on: push`
                         ‚¨á
       GitHub Actions spins up a runner (ubuntu-latest)
                         ‚¨á
     Code is checked out & Docker image is built
                         ‚¨á
       Docker image is pushed to DockerHub registry
                         ‚¨á
        Ready to be deployed via Kubernetes or Compose
```

* * *

## üß™ Test It Yourself

Try pushing a small change inside `ecom_data_sources/unified_simulator.py` and push:

```bash
git add .
git commit -m "trigger CI"
git push origin main
```

Then go to **GitHub ‚Üí Actions tab** and watch your workflow go green ‚úÖ.

* * *

# üß© PART 7: **Complete Flowchart + Developer Cheat Sheet**

This part stitches together everything you‚Äôve built into a visual and conceptual overview. After this, you‚Äôll _fully understand how your `ecom_data_sources` microservice_ works end-to-end with automation, containerization, and deployment in mind.

* * *


## üß∞ **A. DEVELOPER CHEAT SHEET ‚Äî Commands & Roles**

| File | Role | When You Use It |
| --- | --- | --- |
| `start_simulation.sh` | üí• Orchestration Script: Batch ‚Üí API fetch ‚Üí Realtime | Gets executed in container by Dockerfile‚Äôs `CMD` |
| `Dockerfile` | üì¶ Container Blueprint | `make build` or GitHub Action |
| `Makefile` | üß∞ Developer Commands | Run `make build`, `make run`, `make push`, `make test` |
| `.github/workflows/build_simulator.yml` | ü§ñ CI/CD Automation | Triggered on push; builds + pushes to DockerHub |
| `.env.secrets` | üîê Sensitive Info (not committed) | Used locally to login with `make login` |

* * *

## üèóÔ∏è **B. Directory + Execution Plan**

```
ecom_data_sources/
‚îú‚îÄ‚îÄ Dockerfile             ‚Üí Container blueprint
‚îú‚îÄ‚îÄ Makefile               ‚Üí Dev interface (build/run/push)
‚îú‚îÄ‚îÄ start_simulation.sh    ‚Üí Script that drives simulation logic
‚îú‚îÄ‚îÄ requirements.txt       ‚Üí All Python deps
‚îú‚îÄ‚îÄ pos_logs/
‚îÇ   ‚îî‚îÄ‚îÄ unified_simulator.py ‚Üí Main simulator code (batch + realtime)
‚îú‚îÄ‚îÄ external_apis/
‚îÇ   ‚îî‚îÄ‚îÄ promotion_fetch_api_request.py ‚Üí Background API job
‚îú‚îÄ‚îÄ simulation_scripts/
‚îÇ   ‚îî‚îÄ‚îÄ simulator_logic.py ‚Üí Data generation logic
‚îú‚îÄ‚îÄ logs/                  ‚Üí Runtime logs
‚îú‚îÄ‚îÄ json_files/            ‚Üí Batch output
```

* * *

## üîÑ **C. Example Flow (Dev ‚Üí CI/CD ‚Üí Deployment)**

### 1\. üë®‚Äçüíª Local Dev

```bash
cd ecom_data_sources
make build     # Builds Docker container
make run       # Runs container locally
make push      # (After login) pushes image to DockerHub
```

### 2\. üîÅ GitHub Triggered CI/CD

```bash
# Modify and push
git add .
git commit -m "new batch logic"
git push origin main

# GitHub Actions:
# ‚Üí builds Docker image
# ‚Üí pushes to DockerHub
```

### 3\. üöÄ Deployment

That pushed image (`tejasjay03/ecom_data_sources:latest`) can now be pulled by:

-   Your Kubernetes YAML
-   Docker Compose stack
-   Orchestrated Airflow DAG
-   ANY infra that supports containers
* * *

## üéÅ Bonus: Use Cases Across Teams

| Team | Usage |
| --- | --- |
| **Data Eng** | Simulate traffic for pipeline QA |
| **ML Eng** | Train/test new models on synthetic data |
| **DevOps** | Preload production with test events |
| **Security** | Red team testing of fraud flows |
| **Marketing** | Simulate campaign triggers |
| **SRE** | Load testing + pipeline drift detection |

* * *


